{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Load npy data (can't be visualized in IDE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_ppi_features = np.load('./GraphSAGE/example_data/toy-ppi-feats.npy')\n",
    "reddit_features = np.load('./reddit/reddit-feats.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(14755, 50)\n"
     ]
    }
   ],
   "source": [
    "# toy_ppi_features\n",
    "print(type(toy_ppi_features))\n",
    "print(toy_ppi_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(232965, 602)\n",
      "[ 254.    5.    6. ...,   19.    1.   47.]\n"
     ]
    }
   ],
   "source": [
    "# reddit features\n",
    "print(type(reddit_features))\n",
    "print(reddit_features.shape)\n",
    "# print(reddit_features[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test example supervised method with toy_ppi data\n",
    "### Usage:\n",
    "`\n",
    "$ python -m graphsage.supervised_train --train_prefix ./example_data/toy-ppi --model graphsage_mean --sigmoid\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile\n",
      "Dockerfile.gpu\n",
      "eval_scripts\n",
      "example_data\n",
      "example_supervised.sh\n",
      "example_unsupervised.sh\n",
      "graphsage\n",
      "LICENSE.txt\n",
      "README.md\n",
      "requirements.txt\n",
      "Loading training data..\n",
      "Removed 0 nodes that lacked proper annotations due to networkx versioning issues\n",
      "Loaded data.. now preprocessing..\n",
      "Done loading training data..\n",
      "Epoch: 0001\n",
      "Iter: 0000 train_loss= 0.69365 train_f1_mic= 0.35665 train_f1_mac= 0.30926 val_loss= 0.66809 val_f1_mic= 0.40288 val_f1_mac= 0.15399 time= 0.32527\n",
      "Iter: 0005 train_loss= 0.58757 train_f1_mic= 0.38209 train_f1_mac= 0.09720 val_loss= 0.66809 val_f1_mic= 0.40288 val_f1_mac= 0.15399 time= 0.12677\n",
      "Iter: 0010 train_loss= 0.54786 train_f1_mic= 0.39833 train_f1_mac= 0.10215 val_loss= 0.66809 val_f1_mic= 0.40288 val_f1_mac= 0.15399 time= 0.10942\n",
      "Iter: 0015 train_loss= 0.54666 train_f1_mic= 0.37320 train_f1_mac= 0.08884 val_loss= 0.66809 val_f1_mic= 0.40288 val_f1_mac= 0.15399 time= 0.10166\n",
      "Epoch: 0002\n",
      "Iter: 0001 train_loss= 0.54209 train_f1_mic= 0.38601 train_f1_mac= 0.09762 val_loss= 0.58120 val_f1_mic= 0.38683 val_f1_mac= 0.10347 time= 0.09930\n",
      "Iter: 0006 train_loss= 0.54340 train_f1_mic= 0.39818 train_f1_mac= 0.10674 val_loss= 0.58120 val_f1_mic= 0.38683 val_f1_mac= 0.10347 time= 0.09816\n",
      "Iter: 0011 train_loss= 0.53798 train_f1_mic= 0.38143 train_f1_mac= 0.09911 val_loss= 0.58120 val_f1_mic= 0.38683 val_f1_mac= 0.10347 time= 0.09649\n",
      "Iter: 0016 train_loss= 0.52657 train_f1_mic= 0.40471 train_f1_mac= 0.11205 val_loss= 0.58120 val_f1_mic= 0.38683 val_f1_mac= 0.10347 time= 0.09473\n",
      "Epoch: 0003\n",
      "Iter: 0002 train_loss= 0.53568 train_f1_mic= 0.40943 train_f1_mac= 0.12362 val_loss= 0.54804 val_f1_mic= 0.40574 val_f1_mac= 0.12494 time= 0.09381\n",
      "Iter: 0007 train_loss= 0.53155 train_f1_mic= 0.41444 train_f1_mac= 0.12831 val_loss= 0.54804 val_f1_mic= 0.40574 val_f1_mac= 0.12494 time= 0.09171\n",
      "Iter: 0012 train_loss= 0.53359 train_f1_mic= 0.42074 train_f1_mac= 0.13800 val_loss= 0.54804 val_f1_mic= 0.40574 val_f1_mac= 0.12494 time= 0.08984\n",
      "Iter: 0017 train_loss= 0.52046 train_f1_mic= 0.42581 train_f1_mac= 0.14824 val_loss= 0.54804 val_f1_mic= 0.40574 val_f1_mac= 0.12494 time= 0.08873\n",
      "Epoch: 0004\n",
      "Iter: 0003 train_loss= 0.52015 train_f1_mic= 0.44376 train_f1_mac= 0.16223 val_loss= 0.55645 val_f1_mic= 0.42944 val_f1_mac= 0.16209 time= 0.08880\n",
      "Iter: 0008 train_loss= 0.52471 train_f1_mic= 0.41835 train_f1_mac= 0.15133 val_loss= 0.55645 val_f1_mic= 0.42944 val_f1_mac= 0.16209 time= 0.08858\n",
      "Iter: 0013 train_loss= 0.51275 train_f1_mic= 0.44509 train_f1_mac= 0.17442 val_loss= 0.55645 val_f1_mic= 0.42944 val_f1_mac= 0.16209 time= 0.08824\n",
      "Iter: 0018 train_loss= 0.52326 train_f1_mic= 0.44170 train_f1_mac= 0.17299 val_loss= 0.55645 val_f1_mic= 0.42944 val_f1_mac= 0.16209 time= 0.08819\n",
      "Epoch: 0005\n",
      "Iter: 0004 train_loss= 0.51349 train_f1_mic= 0.47746 train_f1_mac= 0.22257 val_loss= 0.53686 val_f1_mic= 0.46886 val_f1_mac= 0.21088 time= 0.08834\n",
      "Iter: 0009 train_loss= 0.51919 train_f1_mic= 0.47648 train_f1_mac= 0.23563 val_loss= 0.53686 val_f1_mic= 0.46886 val_f1_mac= 0.21088 time= 0.08840\n",
      "Iter: 0014 train_loss= 0.51585 train_f1_mic= 0.44290 train_f1_mac= 0.18294 val_loss= 0.53686 val_f1_mic= 0.46886 val_f1_mac= 0.21088 time= 0.08813\n",
      "Epoch: 0006\n",
      "Iter: 0000 train_loss= 0.51052 train_f1_mic= 0.47798 train_f1_mac= 0.22586 val_loss= 0.52565 val_f1_mic= 0.45363 val_f1_mac= 0.21914 time= 0.08854\n",
      "Iter: 0005 train_loss= 0.50488 train_f1_mic= 0.47463 train_f1_mac= 0.22393 val_loss= 0.52565 val_f1_mic= 0.45363 val_f1_mac= 0.21914 time= 0.08997\n",
      "Iter: 0010 train_loss= 0.50905 train_f1_mic= 0.45739 train_f1_mac= 0.20840 val_loss= 0.52565 val_f1_mic= 0.45363 val_f1_mac= 0.21914 time= 0.09005\n",
      "Iter: 0015 train_loss= 0.52553 train_f1_mic= 0.49608 train_f1_mac= 0.26233 val_loss= 0.52565 val_f1_mic= 0.45363 val_f1_mac= 0.21914 time= 0.08991\n",
      "Epoch: 0007\n",
      "Iter: 0001 train_loss= 0.50237 train_f1_mic= 0.45676 train_f1_mac= 0.20960 val_loss= 0.52214 val_f1_mic= 0.47003 val_f1_mac= 0.23159 time= 0.09052\n",
      "Iter: 0006 train_loss= 0.50308 train_f1_mic= 0.48088 train_f1_mac= 0.24809 val_loss= 0.52214 val_f1_mic= 0.47003 val_f1_mac= 0.23159 time= 0.09042\n",
      "Iter: 0011 train_loss= 0.49869 train_f1_mic= 0.50532 train_f1_mac= 0.27933 val_loss= 0.52214 val_f1_mic= 0.47003 val_f1_mac= 0.23159 time= 0.09029\n",
      "Iter: 0016 train_loss= 0.50426 train_f1_mic= 0.48998 train_f1_mac= 0.26226 val_loss= 0.52214 val_f1_mic= 0.47003 val_f1_mac= 0.23159 time= 0.08972\n",
      "Epoch: 0008\n",
      "Iter: 0002 train_loss= 0.51468 train_f1_mic= 0.47058 train_f1_mac= 0.23911 val_loss= 0.53104 val_f1_mic= 0.49823 val_f1_mac= 0.26695 time= 0.08999\n",
      "Iter: 0007 train_loss= 0.50834 train_f1_mic= 0.48458 train_f1_mac= 0.25603 val_loss= 0.53104 val_f1_mic= 0.49823 val_f1_mac= 0.26695 time= 0.08959\n",
      "Iter: 0012 train_loss= 0.50744 train_f1_mic= 0.46239 train_f1_mac= 0.22390 val_loss= 0.53104 val_f1_mic= 0.49823 val_f1_mac= 0.26695 time= 0.08996\n",
      "Iter: 0017 train_loss= 0.51132 train_f1_mic= 0.48691 train_f1_mac= 0.27298 val_loss= 0.53104 val_f1_mic= 0.49823 val_f1_mac= 0.26695 time= 0.08960\n",
      "Epoch: 0009\n",
      "Iter: 0003 train_loss= 0.51160 train_f1_mic= 0.50881 train_f1_mac= 0.28550 val_loss= 0.52408 val_f1_mic= 0.52252 val_f1_mac= 0.31483 time= 0.08964\n",
      "Iter: 0008 train_loss= 0.49773 train_f1_mic= 0.49134 train_f1_mac= 0.26090 val_loss= 0.52408 val_f1_mic= 0.52252 val_f1_mac= 0.31483 time= 0.08998\n",
      "Iter: 0013 train_loss= 0.50170 train_f1_mic= 0.47990 train_f1_mac= 0.27077 val_loss= 0.52408 val_f1_mic= 0.52252 val_f1_mac= 0.31483 time= 0.09006\n",
      "Iter: 0018 train_loss= 0.49672 train_f1_mic= 0.51907 train_f1_mac= 0.28312 val_loss= 0.52408 val_f1_mic= 0.52252 val_f1_mac= 0.31483 time= 0.09000\n",
      "Epoch: 0010\n",
      "Iter: 0004 train_loss= 0.48810 train_f1_mic= 0.51788 train_f1_mac= 0.31240 val_loss= 0.51267 val_f1_mic= 0.49112 val_f1_mac= 0.26616 time= 0.09022\n",
      "Iter: 0009 train_loss= 0.48542 train_f1_mic= 0.51600 train_f1_mac= 0.30461 val_loss= 0.51267 val_f1_mic= 0.49112 val_f1_mac= 0.26616 time= 0.09012\n",
      "Iter: 0014 train_loss= 0.49189 train_f1_mic= 0.50146 train_f1_mac= 0.28118 val_loss= 0.51267 val_f1_mic= 0.49112 val_f1_mac= 0.26616 time= 0.08995\n",
      "Optimization Finished!\n",
      "Full validation stats: loss= 0.50922 f1_micro= 0.51313 f1_macro= 0.31319 time= 0.24655\n",
      "Writing test set stats to file (don't peak!)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-20 00:34:00.779614: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd GraphSAGE\n",
    "./example_supervised.sh\n",
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Train and Test example unsupervised method with toy_ppi data\n",
    "### Usage:\n",
    "`\n",
    "$ python -m graphsage.unsupervised_train --train_prefix ./example_data/toy-ppi --model graphsage_mean --max_total_steps 1000 --validate_iter 10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile\n",
      "Dockerfile.gpu\n",
      "eval_scripts\n",
      "example_data\n",
      "example_supervised.sh\n",
      "example_unsupervised.sh\n",
      "graphsage\n",
      "LICENSE.txt\n",
      "README.md\n",
      "requirements.txt\n",
      "sup-example_data\n",
      "Loading training data..\n",
      "Removed 0 nodes that lacked proper annotations due to networkx versioning issues\n",
      "Loaded data.. now preprocessing..\n",
      "Done loading training data..\n",
      "Unexpected missing: 0\n",
      "9716 train nodes\n",
      "5039 test nodes\n",
      "Epoch: 0001\n",
      "Iter: 0000 train_loss= 18.42027 train_mrr= 0.21211 train_mrr_ema= 0.21211 val_loss= 18.56255 val_mrr= 0.21497 val_mrr_ema= 0.21497 time= 0.98052\n",
      "Iter: 0050 train_loss= 18.10417 train_mrr= 0.19661 train_mrr_ema= 0.20350 val_loss= 18.28430 val_mrr= 0.21614 val_mrr_ema= 0.20895 time= 0.22023\n",
      "Iter: 0100 train_loss= 17.89622 train_mrr= 0.19866 train_mrr_ema= 0.19781 val_loss= 17.97742 val_mrr= 0.17841 val_mrr_ema= 0.21105 time= 0.20411\n",
      "Iter: 0150 train_loss= 17.38004 train_mrr= 0.18559 train_mrr_ema= 0.19201 val_loss= 17.78714 val_mrr= 0.18837 val_mrr_ema= 0.21276 time= 0.20331\n",
      "Iter: 0200 train_loss= 16.65871 train_mrr= 0.21734 train_mrr_ema= 0.18801 val_loss= 17.24492 val_mrr= 0.18201 val_mrr_ema= 0.20773 time= 0.20163\n",
      "Iter: 0250 train_loss= 16.59473 train_mrr= 0.19877 train_mrr_ema= 0.18709 val_loss= 16.79966 val_mrr= 0.18273 val_mrr_ema= 0.21201 time= 0.19112\n",
      "Iter: 0300 train_loss= 16.51816 train_mrr= 0.17747 train_mrr_ema= 0.18673 val_loss= 16.32756 val_mrr= 0.23259 val_mrr_ema= 0.20130 time= 0.18323\n",
      "Iter: 0350 train_loss= 16.16482 train_mrr= 0.19685 train_mrr_ema= 0.18653 val_loss= 16.11158 val_mrr= 0.22699 val_mrr_ema= 0.20480 time= 0.18067\n",
      "Iter: 0400 train_loss= 15.74123 train_mrr= 0.18708 train_mrr_ema= 0.18695 val_loss= 15.77972 val_mrr= 0.20505 val_mrr_ema= 0.20667 time= 0.18089\n",
      "Iter: 0450 train_loss= 15.45857 train_mrr= 0.19306 train_mrr_ema= 0.18700 val_loss= 15.62625 val_mrr= 0.20490 val_mrr_ema= 0.20686 time= 0.17852\n",
      "Iter: 0500 train_loss= 15.22509 train_mrr= 0.20557 train_mrr_ema= 0.18668 val_loss= 15.42017 val_mrr= 0.22615 val_mrr_ema= 0.20836 time= 0.17825\n",
      "Iter: 0550 train_loss= 15.20396 train_mrr= 0.19354 train_mrr_ema= 0.18640 val_loss= 15.29812 val_mrr= 0.21626 val_mrr_ema= 0.21010 time= 0.17931\n",
      "Iter: 0600 train_loss= 15.05204 train_mrr= 0.18133 train_mrr_ema= 0.18730 val_loss= 15.13898 val_mrr= 0.18076 val_mrr_ema= 0.20750 time= 0.18076\n",
      "Iter: 0650 train_loss= 14.95037 train_mrr= 0.16723 train_mrr_ema= 0.18775 val_loss= 15.07821 val_mrr= 0.21610 val_mrr_ema= 0.20166 time= 0.18141\n",
      "Iter: 0700 train_loss= 14.89808 train_mrr= 0.19851 train_mrr_ema= 0.18535 val_loss= 14.92153 val_mrr= 0.20890 val_mrr_ema= 0.20901 time= 0.18251\n",
      "Iter: 0750 train_loss= 14.82336 train_mrr= 0.15954 train_mrr_ema= 0.18376 val_loss= 14.87786 val_mrr= 0.20380 val_mrr_ema= 0.20969 time= 0.18405\n",
      "Iter: 0800 train_loss= 14.75249 train_mrr= 0.17652 train_mrr_ema= 0.18488 val_loss= 14.81701 val_mrr= 0.21432 val_mrr_ema= 0.20933 time= 0.18525\n",
      "Iter: 0850 train_loss= 14.74393 train_mrr= 0.17767 train_mrr_ema= 0.18596 val_loss= 14.76785 val_mrr= 0.20444 val_mrr_ema= 0.21231 time= 0.18544\n",
      "Iter: 0900 train_loss= 14.67400 train_mrr= 0.21695 train_mrr_ema= 0.18608 val_loss= 14.73264 val_mrr= 0.21637 val_mrr_ema= 0.21403 time= 0.18506\n",
      "Iter: 0950 train_loss= 14.66165 train_mrr= 0.18561 train_mrr_ema= 0.18591 val_loss= 14.71418 val_mrr= 0.18163 val_mrr_ema= 0.21425 time= 0.18505\n",
      "Iter: 1000 train_loss= 14.70443 train_mrr= 0.18287 train_mrr_ema= 0.18518 val_loss= 14.67829 val_mrr= 0.22399 val_mrr_ema= 0.21334 time= 0.18477\n",
      "Optimization Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-20 00:38:23.969714: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd GraphSAGE\n",
    "./example_unsupervised.sh\n",
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsup_embedding = np.load('./GraphSAGE/unsup-example_data/graphsage_mean_small_0.000010/val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14755, 256)\n"
     ]
    }
   ],
   "source": [
    "print (unsup_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0619909  -0.04743333  0.02801189  0.03058914 -0.14002779 -0.070545\n",
      " -0.02199555  0.04056363 -0.06709529 -0.01428938]\n"
     ]
    }
   ],
   "source": [
    "print (unsup_embedding[0:10 , 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
